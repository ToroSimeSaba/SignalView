import SwiftUI
import Vision
import AVFoundation

extension ContentView {
    /// ğŸ”¹ä¿¡å·æ©ŸãŒã‚ã‚Œã°æœ€å¤§3ã¤åˆ‡ã‚Šå‡ºã—ã¦zoomedImagesã«ã‚»ãƒƒãƒˆï¼ˆ2ç§’ã§æ¶ˆå»ï¼‰
    func updateZoomedImages(objects: [VNRecognizedObjectObservation]) {
        var newImages: [UIImage] = []
        var newSignalColors: [(label: String, color: String)] = []
        let maxHistoryCount = 10 // ç›´è¿‘10ãƒ•ãƒ¬ãƒ¼ãƒ ã§æŠ•ç¥¨
        
        for obj in objects {
            if let label = obj.labels.first {
                let translated = JapaneseLabels.translate(label.identifier)
                if translated == "ä¿¡å·æ©Ÿ",
                   let frame = currentFrameImage ,
                   let cropped = cropImage(originalImage: frame, boundingBox: obj.boundingBox) {
                    
                    // âœ… è‰²åˆ¤å®š
                    let color = detectTrafficLightColor(from: cropped)
                    print("ä¿¡å·æ©Ÿè‰²åˆ¤å®š: \(color)")
                  
                    // âœ… å±¥æ­´æ›´æ–°
                    recentSignalColors.append(color)
                    if recentSignalColors.count > maxHistoryCount {
                        recentSignalColors.removeFirst()
                    }
                    
                    // âœ… é…åˆ—ã«è¿½åŠ 
                    newSignalColors.append((label: translated, color: color))
                    
                    newImages.append(cropped)
                    if newImages.count >= 3 { break } // æœ€å¤§3ã¤
                }
            }
        }
        
        // âœ… æŠ•ç¥¨ã«ã‚ˆã‚‹æœ€çµ‚åˆ¤æ–­
        if !recentSignalColors.isEmpty {
            let mostCommonColor = recentSignalColors
                .reduce(into: [:]) { counts, c in counts[c, default: 0] += 1 }
                .max { $0.value < $1.value }?.key ?? ""
            
            // âœ… åˆ‡ã‚Šæ›¿ã‚ã‚Šæ™‚ã®ã¿å±¥æ­´ãƒªã‚»ãƒƒãƒˆï¼‹èª­ã¿ä¸Šã’
            if mostCommonColor != lastDetectedColor && mostCommonColor != "" {
                lastDetectedColor = mostCommonColor
                recentSignalColors = [mostCommonColor] // æ–°ã—ã„è‰²ãŒå„ªå‹¢ã«ãªã£ãŸã®ã§å±¥æ­´ãƒªã‚»ãƒƒãƒˆ
                speak("ä¿¡å·æ©Ÿã¯ã€ \(mostCommonColor) ã§ã™")
            }
        }
        
        // âœ… æ–°ã—ã„è‰²ãƒ©ãƒ™ãƒ«ã‚’æ›´æ–°
        signalColors = newSignalColors
        
        if !newImages.isEmpty {
            zoomedImages = newImages
            signalColors = newSignalColors
            lastUpdateTime = Date()
            
            // âœ… ğŸ”¹ã€Œå¤‰åŒ–ã—ãŸè‰²ã®ã¿èª­ã¿ä¸Šã’ã‚‹ã€
            let newColorsOnly = newSignalColors.map { $0.color }
            if newColorsOnly != lastSpokenColors { // å¤‰åŒ–ãŒã‚ã‚Œã°
                if let latest = newSignalColors.first {
                    speak("ä¿¡å·æ©Ÿã¯ \(latest.color) ã§ã™")
                }
                lastSpokenColors = newColorsOnly
            }
            
            // âœ… 3ç§’å¾Œã«ã€Œæœ€å¾Œã®æ›´æ–°ã‹ã‚‰3ç§’çµŒéã—ã¦ã„ã‚‹ã‹ã€ã‚’ç¢ºèª
            DispatchQueue.main.asyncAfter(deadline: .now() + 3) {
                if Date().timeIntervalSince(lastUpdateTime) >= 3 {
                    zoomedImages = []
                    signalColors = []
//                    lastSpokenColors = []
                }
            }
        } else {
            // âœ… æ¤œå‡ºãŒãªãã¦ã‚‚ã€å‰å›ã®æ›´æ–°ã‹ã‚‰3ç§’çµŒéã™ã‚‹ã¾ã§ã¯æ®‹ã™
            if Date().timeIntervalSince(lastUpdateTime) >= 3 {
                zoomedImages = []
                signalColors = []
//                lastSpokenColors = []
            }
        }
    }
    
    // èª­ã¿ä¸Šã’
    func speak(_ text: String) {
        if Date().timeIntervalSince(lastSpeechTime) < 2 { return } // 1ç§’ä»¥å†…ã¯ç„¡è¦–
        lastSpeechTime = Date()
        // âœ… ã™ã§ã«èª­ã¿ä¸Šã’ä¸­ãªã‚‰å³åº§ã«åœæ­¢
        if speechSynthesizer.isSpeaking {
            speechSynthesizer.stopSpeaking(at: .immediate)
        }
        
        let utterance = AVSpeechUtterance(string: text)
        utterance.voice = AVSpeechSynthesisVoice(language: "ja-JP")
        utterance.rate = 0.75  // âœ… èª­ã¿ä¸Šã’é€Ÿåº¦ï¼ˆ0.0ã€œ1.0ï¼‰
        speechSynthesizer.speak(utterance)
    }
}
